{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stage2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFejSxtjjbBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb0fe706-fb94-4514-cd5d-6313efc86817"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfYi6FN-jfE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "75cce5f8-986f-4ec5-cafc-550ca3001ba3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep 12 04:59:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogjJYJrSrnX1"
      },
      "source": [
        "! mkdir /root/.kaggle\n",
        "! cp '/content/drive/My Drive/kaggle.json' /root/.kaggle\n",
        "! chmod 400 /root/.kaggle/kaggle.json\n",
        "\n",
        "!pip uninstall -y kaggle >> quit\n",
        "!pip install --upgrade pip >> quit\n",
        "!pip install kaggle==1.5.6 >> quit\n",
        "!kaggle -v >> quit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfm1LmVtr0na",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "694788c0-7a05-4edc-8a39-7268d2dae1e2"
      },
      "source": [
        "%%time\n",
        "!kaggle datasets download -d gopidurgaprasad/birdsong-stage1-1sec\n",
        "!unzip birdsong-stage1-1sec.zip >> quit\n",
        "!rm birdsong-stage1-1sec.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading birdsong-stage1-1sec.zip to /content\n",
            "100% 8.67G/8.68G [03:40<00:00, 59.1MB/s]\n",
            "100% 8.68G/8.68G [03:40<00:00, 42.2MB/s]\n",
            "CPU times: user 1.41 s, sys: 282 ms, total: 1.69 s\n",
            "Wall time: 9min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Q0zQPQr5Ty",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "651e4f6b-4d82-4c43-d331-3d5975e461b0"
      },
      "source": [
        "%%time\n",
        "!kaggle datasets download -d gopidurgaprasad/birdsong-stage1-1sec-sudo-5\n",
        "!unzip birdsong-stage1-1sec-sudo-5.zip >> quit\n",
        "!rm birdsong-stage1-1sec-sudo-5.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading birdsong-stage1-1sec-sudo-5.zip to /content\n",
            "100% 3.26G/3.26G [01:49<00:00, 61.6MB/s]\n",
            "100% 3.26G/3.26G [01:49<00:00, 31.9MB/s]\n",
            "CPU times: user 501 ms, sys: 98.4 ms, total: 599 ms\n",
            "Wall time: 3min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZuxUthy266"
      },
      "source": [
        "!pip install soundfile >> quit\n",
        "!pip install catalyst >> quit\n",
        "!pip install torchaudio >> quit\n",
        "!pip install torchlibrosa >> quit\n",
        "!pip install timm >> quit\n",
        "!pip install audiomentations >> quit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFNxyjztBVX"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNx1L4XAtBRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b9032f72-1f4c-4a5a-a0ea-c65c1f740cc7"
      },
      "source": [
        "stage1_wav = glob.glob(\"/content/train_stage1_1sec/tmp/birdsongWav/train_stage1_1sec/*.wav\")\n",
        "stage1_sudo_wav = glob.glob(\"/content/train_stage1_1sec_sudo/tmp/birdsongWav/train_stage1_1sec_sudo/*.wav\")\n",
        "\n",
        "stage1_wav = stage1_wav + stage1_sudo_wav\n",
        "\n",
        "stage1_wav_df = pd.DataFrame()\n",
        "stage1_wav_df[\"path\"] = stage1_wav\n",
        "stage1_wav_df[\"filename\"] = stage1_wav_df[\"path\"].apply(lambda x: x.split('/')[-1].strip('.wav'))\n",
        "\n",
        "stage1_df = pd.read_csv(\"stage1_df.csv\")\n",
        "stage1_df[\"filename\"] = stage1_df[\"file_name\"].apply(lambda x: x.split('/')[-1].strip('.wav'))\n",
        "stage1_df = stage1_df.merge(stage1_wav_df, on=\"filename\", how=\"left\")\n",
        "\n",
        "stage1_sudo_df = pd.read_csv(\"stage1_sudo.csv\")\n",
        "stage1_sudo_df[\"filename\"] = stage1_sudo_df[\"file_name\"].apply(lambda x: x.split('/')[-1].strip('.wav'))\n",
        "stage1_sudo_df = stage1_sudo_df.merge(stage1_wav_df, on=\"filename\", how=\"left\")\n",
        "\n",
        "stage1_df = stage1_df.append(stage1_sudo_df)\n",
        "\n",
        "stage1_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ebird_code</th>\n",
              "      <th>file_name</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>pred_prob</th>\n",
              "      <th>pred_code</th>\n",
              "      <th>kfold</th>\n",
              "      <th>filename</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logshr</td>\n",
              "      <td>../input/birdsong-wav-02/tmp/birdsongWav/train...</td>\n",
              "      <td>146</td>\n",
              "      <td>1.0</td>\n",
              "      <td>logshr</td>\n",
              "      <td>1</td>\n",
              "      <td>XC255302_31</td>\n",
              "      <td>/content/train_stage1_1sec/tmp/birdsongWav/tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eastow</td>\n",
              "      <td>../input/birdsong-wav-01/tmp/birdsongWav/train...</td>\n",
              "      <td>93</td>\n",
              "      <td>1.0</td>\n",
              "      <td>eastow</td>\n",
              "      <td>3</td>\n",
              "      <td>XC319606_46</td>\n",
              "      <td>/content/train_stage1_1sec/tmp/birdsongWav/tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>easblu</td>\n",
              "      <td>../input/birdsong-wav-01/tmp/birdsongWav/train...</td>\n",
              "      <td>89</td>\n",
              "      <td>1.0</td>\n",
              "      <td>easblu</td>\n",
              "      <td>0</td>\n",
              "      <td>XC502284_26</td>\n",
              "      <td>/content/train_stage1_1sec/tmp/birdsongWav/tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>linspa</td>\n",
              "      <td>../input/birdsong-wav-02/tmp/birdsongWav/train...</td>\n",
              "      <td>143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>linspa</td>\n",
              "      <td>1</td>\n",
              "      <td>XC483715_35</td>\n",
              "      <td>/content/train_stage1_1sec/tmp/birdsongWav/tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>linspa</td>\n",
              "      <td>../input/birdsong-wav-02/tmp/birdsongWav/train...</td>\n",
              "      <td>143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>linspa</td>\n",
              "      <td>1</td>\n",
              "      <td>XC445186_62</td>\n",
              "      <td>/content/train_stage1_1sec/tmp/birdsongWav/tra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ebird_code  ...                                               path\n",
              "0     logshr  ...  /content/train_stage1_1sec/tmp/birdsongWav/tra...\n",
              "1     eastow  ...  /content/train_stage1_1sec/tmp/birdsongWav/tra...\n",
              "2     easblu  ...  /content/train_stage1_1sec/tmp/birdsongWav/tra...\n",
              "3     linspa  ...  /content/train_stage1_1sec/tmp/birdsongWav/tra...\n",
              "4     linspa  ...  /content/train_stage1_1sec/tmp/birdsongWav/tra...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nmwQ477tBOV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfb26e72-7142-4b70-a129-4f10ebf40a2f"
      },
      "source": [
        "stage1_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(508712, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahv8KqQtymNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "81fc5565-14f2-4617-8810-4d0e5cb114f4"
      },
      "source": [
        "stage1_df.kfold.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    106505\n",
              "2    102991\n",
              "1    102384\n",
              "3    101895\n",
              "4     94937\n",
              "Name: kfold, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBdrFWQOyTDM"
      },
      "source": [
        "stage1_df.to_csv(\"drive/My Drive/Cornell Birdcall Identification/input/stage1_sudo.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1UHNgyFtBCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19541ca6-ebd0-4c27-9bc7-c15dbe4a5116"
      },
      "source": [
        "%%writefile pytorch_utils.py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def move_data_to_device(x, device):\n",
        "    if 'float' in str(x.dtype):\n",
        "        x = torch.Tensor(x)\n",
        "    elif 'int' in str(x.dtype):\n",
        "        x = torch.LongTensor(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return x.to(device)\n",
        "\n",
        "\n",
        "def do_mixup(x, mixup_lambda):\n",
        "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
        "    (1, 3, 5, ...).\n",
        "    Args:\n",
        "      x: (batch_size * 2, ...)\n",
        "      mixup_lambda: (batch_size * 2,)\n",
        "    Returns:\n",
        "      out: (batch_size, ...)\n",
        "    \"\"\"\n",
        "    \n",
        "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
        "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
        "        \n",
        "    return out\n",
        "\n",
        "class Mixup(object):\n",
        "    def __init__(self, mixup_alpha, random_seed=1234):\n",
        "        \"\"\"Mixup coefficient generator.\n",
        "        \"\"\"\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "        self.random_state = np.random.RandomState(random_seed)\n",
        "\n",
        "    def get_lambda(self, batch_size):\n",
        "        \"\"\"Get mixup random coefficients.\n",
        "        Args:\n",
        "          batch_size: int\n",
        "        Returns:\n",
        "          mixup_lambdas: (batch_size,)\n",
        "        \"\"\"\n",
        "        mixup_lambdas = []\n",
        "        for n in range(0, batch_size, 2):\n",
        "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
        "            mixup_lambdas.append(lam)\n",
        "            mixup_lambdas.append(1. - lam)\n",
        "\n",
        "        return np.array(mixup_lambdas)\n",
        "    \n",
        "\n",
        "def append_to_dict(dict, key, value):\n",
        "    if key in dict.keys():\n",
        "        dict[key].append(value)\n",
        "    else:\n",
        "        dict[key] = [value]\n",
        "\n",
        "\n",
        "def forward(model, generator, return_input=False, \n",
        "    return_target=False):\n",
        "    \"\"\"Forward data to a model.\n",
        "    \n",
        "    Args: \n",
        "      model: object\n",
        "      generator: object\n",
        "      return_input: bool\n",
        "      return_target: bool\n",
        "    Returns:\n",
        "      audio_name: (audios_num,)\n",
        "      clipwise_output: (audios_num, classes_num)\n",
        "      (ifexist) segmentwise_output: (audios_num, segments_num, classes_num)\n",
        "      (ifexist) framewise_output: (audios_num, frames_num, classes_num)\n",
        "      (optional) return_input: (audios_num, segment_samples)\n",
        "      (optional) return_target: (audios_num, classes_num)\n",
        "    \"\"\"\n",
        "    output_dict = {}\n",
        "    device = next(model.parameters()).device\n",
        "    time1 = time.time()\n",
        "\n",
        "    # Forward data to a model in mini-batches\n",
        "    for n, batch_data_dict in enumerate(generator):\n",
        "        print(n)\n",
        "        batch_waveform = move_data_to_device(batch_data_dict['waveform'], device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            batch_output = model(batch_waveform)\n",
        "\n",
        "        append_to_dict(output_dict, 'audio_name', batch_data_dict['audio_name'])\n",
        "\n",
        "        append_to_dict(output_dict, 'clipwise_output', \n",
        "            batch_output['clipwise_output'].data.cpu().numpy())\n",
        "\n",
        "        if 'segmentwise_output' in batch_output.keys():\n",
        "            append_to_dict(output_dict, 'segmentwise_output', \n",
        "                batch_output['segmentwise_output'].data.cpu().numpy())\n",
        "\n",
        "        if 'framewise_output' in batch_output.keys():\n",
        "            append_to_dict(output_dict, 'framewise_output', \n",
        "                batch_output['framewise_output'].data.cpu().numpy())\n",
        "            \n",
        "        if return_input:\n",
        "            append_to_dict(output_dict, 'waveform', batch_data_dict['waveform'])\n",
        "            \n",
        "        if return_target:\n",
        "            if 'target' in batch_data_dict.keys():\n",
        "                append_to_dict(output_dict, 'target', batch_data_dict['target'])\n",
        "\n",
        "        if n % 10 == 0:\n",
        "            print(' --- Inference time: {:.3f} s / 10 iterations ---'.format(\n",
        "                time.time() - time1))\n",
        "            time1 = time.time()\n",
        "\n",
        "    for key in output_dict.keys():\n",
        "        output_dict[key] = np.concatenate(output_dict[key], axis=0)\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "def interpolate(x, ratio):\n",
        "    \"\"\"Interpolate data in time domain. This is used to compensate the \n",
        "    resolution reduction in downsampling of a CNN.\n",
        "    \n",
        "    Args:\n",
        "      x: (batch_size, time_steps, classes_num)\n",
        "      ratio: int, ratio to interpolate\n",
        "    Returns:\n",
        "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
        "    \"\"\"\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    return upsampled\n",
        "\n",
        "\n",
        "def pad_framewise_output(framewise_output, frames_num):\n",
        "    \"\"\"Pad framewise_output to the same length as input frames. The pad value \n",
        "    is the same as the value of the last frame.\n",
        "    Args:\n",
        "      framewise_output: (batch_size, frames_num, classes_num)\n",
        "      frames_num: int, number of frames to pad\n",
        "    Outputs:\n",
        "      output: (batch_size, frames_num, classes_num)\n",
        "    \"\"\"\n",
        "    pad = framewise_output[:, -1 :, :].repeat(1, frames_num - framewise_output.shape[1], 1)\n",
        "    \"\"\"tensor for padding\"\"\"\n",
        "\n",
        "    output = torch.cat((framewise_output, pad), dim=1)\n",
        "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def count_flops(model, audio_length):\n",
        "    \"\"\"Count flops. Code modified from others' implementation.\n",
        "    \"\"\"\n",
        "    multiply_adds = True\n",
        "    list_conv2d=[]\n",
        "    def conv2d_hook(self, input, output):\n",
        "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
        "        output_channels, output_height, output_width = output[0].size()\n",
        " \n",
        "        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n",
        "        bias_ops = 1 if self.bias is not None else 0\n",
        " \n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_height * output_width\n",
        " \n",
        "        list_conv2d.append(flops)\n",
        "\n",
        "    list_conv1d=[]\n",
        "    def conv1d_hook(self, input, output):\n",
        "        batch_size, input_channels, input_length = input[0].size()\n",
        "        output_channels, output_length = output[0].size()\n",
        " \n",
        "        kernel_ops = self.kernel_size[0] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n",
        "        bias_ops = 1 if self.bias is not None else 0\n",
        " \n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_length\n",
        " \n",
        "        list_conv1d.append(flops)\n",
        " \n",
        "    list_linear=[] \n",
        "    def linear_hook(self, input, output):\n",
        "        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n",
        " \n",
        "        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n",
        "        bias_ops = self.bias.nelement()\n",
        " \n",
        "        flops = batch_size * (weight_ops + bias_ops)\n",
        "        list_linear.append(flops)\n",
        " \n",
        "    list_bn=[] \n",
        "    def bn_hook(self, input, output):\n",
        "        list_bn.append(input[0].nelement() * 2)\n",
        " \n",
        "    list_relu=[] \n",
        "    def relu_hook(self, input, output):\n",
        "        list_relu.append(input[0].nelement() * 2)\n",
        " \n",
        "    list_pooling2d=[]\n",
        "    def pooling2d_hook(self, input, output):\n",
        "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
        "        output_channels, output_height, output_width = output[0].size()\n",
        " \n",
        "        kernel_ops = self.kernel_size * self.kernel_size\n",
        "        bias_ops = 0\n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_height * output_width\n",
        " \n",
        "        list_pooling2d.append(flops)\n",
        "\n",
        "    list_pooling1d=[]\n",
        "    def pooling1d_hook(self, input, output):\n",
        "        batch_size, input_channels, input_length = input[0].size()\n",
        "        output_channels, output_length = output[0].size()\n",
        " \n",
        "        kernel_ops = self.kernel_size[0]\n",
        "        bias_ops = 0\n",
        "        \n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_length\n",
        " \n",
        "        list_pooling2d.append(flops)\n",
        " \n",
        "    def foo(net):\n",
        "        childrens = list(net.children())\n",
        "        if not childrens:\n",
        "            if isinstance(net, nn.Conv2d):\n",
        "                net.register_forward_hook(conv2d_hook)\n",
        "            elif isinstance(net, nn.Conv1d):\n",
        "                net.register_forward_hook(conv1d_hook)\n",
        "            elif isinstance(net, nn.Linear):\n",
        "                net.register_forward_hook(linear_hook)\n",
        "            elif isinstance(net, nn.BatchNorm2d) or isinstance(net, nn.BatchNorm1d):\n",
        "                net.register_forward_hook(bn_hook)\n",
        "            elif isinstance(net, nn.ReLU):\n",
        "                net.register_forward_hook(relu_hook)\n",
        "            elif isinstance(net, nn.AvgPool2d) or isinstance(net, nn.MaxPool2d):\n",
        "                net.register_forward_hook(pooling2d_hook)\n",
        "            elif isinstance(net, nn.AvgPool1d) or isinstance(net, nn.MaxPool1d):\n",
        "                net.register_forward_hook(pooling1d_hook)\n",
        "            else:\n",
        "                print('Warning: flop of module {} is not counted!'.format(net))\n",
        "            return\n",
        "        for c in childrens:\n",
        "            foo(c)\n",
        "\n",
        "    # Register hook\n",
        "    foo(model)\n",
        "    \n",
        "    device = device = next(model.parameters()).device\n",
        "    input = torch.rand(1, audio_length).to(device)\n",
        "\n",
        "    out = model(input)\n",
        " \n",
        "    total_flops = sum(list_conv2d) + sum(list_conv1d) + sum(list_linear) + \\\n",
        "        sum(list_bn) + sum(list_relu) + sum(list_pooling2d) + sum(list_pooling1d)\n",
        "    \n",
        "    return total_flops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing pytorch_utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51NIk7DXtA0X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2beafc27-653d-42f6-b75e-f9af82dbb32e"
      },
      "source": [
        "%%writefile classifiers.py\n",
        "\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from timm.models.efficientnet import tf_efficientnet_b4_ns, tf_efficientnet_b3_ns, \\\n",
        "    tf_efficientnet_b5_ns, tf_efficientnet_b2_ns, tf_efficientnet_b6_ns, tf_efficientnet_b7_ns, tf_efficientnet_b0_ns\n",
        "from torch import nn\n",
        "from torch.nn.modules.dropout import Dropout\n",
        "from torch.nn.modules.linear import Linear\n",
        "from torch.nn.modules.pooling import AdaptiveAvgPool2d, AdaptiveMaxPool2d\n",
        "\n",
        "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
        "from torchlibrosa.augmentation import SpecAugmentation\n",
        "\n",
        "from pytorch_utils import do_mixup, interpolate, pad_framewise_output\n",
        "\n",
        "encoder_params = {\n",
        "    \"resnest50d\" : {\n",
        "        \"features\" : 2048,\n",
        "        \"init_op\"  : partial(timm.models.resnest50d, pretrained=True, in_chans=1)\n",
        "    },\n",
        "    \"densenet201\" : {\n",
        "        \"features\": 1920,\n",
        "        \"init_op\": partial(timm.models.densenet201, pretrained=True)\n",
        "    },\n",
        "    \"dpn92\" : {\n",
        "        \"features\": 2688,\n",
        "        \"init_op\": partial(timm.models.dpn92, pretrained=True)\n",
        "    },\n",
        "    \"dpn131\": {\n",
        "        \"features\": 2688,\n",
        "        \"init_op\": partial(timm.models.dpn131, pretrained=True)\n",
        "    },\n",
        "    \"tf_efficientnet_b0_ns\": {\n",
        "        \"features\": 1280,\n",
        "        \"init_op\": partial(tf_efficientnet_b0_ns, pretrained=True, drop_path_rate=0.2)\n",
        "    },\n",
        "    \"tf_efficientnet_b3_ns\": {\n",
        "        \"features\": 1536,\n",
        "        \"init_op\": partial(tf_efficientnet_b3_ns, pretrained=True, drop_path_rate=0.2)\n",
        "    },\n",
        "    \"tf_efficientnet_b2_ns\": {\n",
        "        \"features\": 1408,\n",
        "        \"init_op\": partial(tf_efficientnet_b2_ns, pretrained=True, drop_path_rate=0.2)\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def init_layer(layer):\n",
        "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        " \n",
        "    if hasattr(layer, 'bias'):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "            \n",
        "    \n",
        "def init_bn(bn):\n",
        "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \n",
        "        super(ConvBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=(3, 3), stride=(1, 1),\n",
        "                              padding=(1, 1), bias=False)\n",
        "                              \n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=(3, 3), stride=(1, 1),\n",
        "                              padding=(1, 1), bias=False)\n",
        "                              \n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.init_weight()\n",
        "        \n",
        "    def init_weight(self):\n",
        "        init_layer(self.conv1)\n",
        "        init_layer(self.conv2)\n",
        "        init_bn(self.bn1)\n",
        "        init_bn(self.bn2)\n",
        "\n",
        "        \n",
        "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
        "        \n",
        "        x = input\n",
        "        x = F.relu_(self.bn1(self.conv1(x)))\n",
        "        x = F.relu_(self.bn2(self.conv2(x)))\n",
        "        if pool_type == 'max':\n",
        "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg':\n",
        "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg+max':\n",
        "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            x = x1 + x2\n",
        "        else:\n",
        "            raise Exception('Incorrect argument!')\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvBlock5x5(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \n",
        "        super(ConvBlock5x5, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=(5, 5), stride=(1, 1),\n",
        "                              padding=(2, 2), bias=False)\n",
        "                              \n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.init_weight()\n",
        "        \n",
        "    def init_weight(self):\n",
        "        init_layer(self.conv1)\n",
        "        init_bn(self.bn1)\n",
        "\n",
        "        \n",
        "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
        "        \n",
        "        x = input\n",
        "        x = F.relu_(self.bn1(self.conv1(x)))\n",
        "        if pool_type == 'max':\n",
        "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg':\n",
        "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg+max':\n",
        "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            x = x1 + x2\n",
        "        else:\n",
        "            raise Exception('Incorrect argument!')\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class AttBlock(nn.Module):\n",
        "    def __init__(self, n_in, n_out, activation='linear', temperature=1.):\n",
        "        super(AttBlock, self).__init__()\n",
        "        \n",
        "        self.activation = activation\n",
        "        self.temperature = temperature\n",
        "        self.att = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.cla = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        \n",
        "        self.bn_att = nn.BatchNorm1d(n_out)\n",
        "        self.init_weights()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        init_layer(self.att)\n",
        "        init_layer(self.cla)\n",
        "        init_bn(self.bn_att)\n",
        "         \n",
        "    def forward(self, x):\n",
        "        # x: (n_samples, n_in, n_time)\n",
        "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
        "        cla = self.nonlinear_transform(self.cla(x))\n",
        "        x = torch.sum(norm_att * cla, dim=2)\n",
        "        return x, norm_att, cla\n",
        "\n",
        "    def nonlinear_transform(self, x):\n",
        "        if self.activation == 'linear':\n",
        "            return x\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class Cnn14_16k(nn.Module):\n",
        "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
        "        \n",
        "        super(Cnn14_16k, self).__init__() \n",
        "\n",
        "        assert sample_rate == 16000\n",
        "        assert window_size == 512\n",
        "        assert hop_size == 160\n",
        "        assert mel_bins == 64\n",
        "        assert fmin == 50\n",
        "        assert fmax == 8000\n",
        "\n",
        "        window = 'hann'\n",
        "        center = True\n",
        "        pad_mode = 'reflect'\n",
        "        ref = 1.0\n",
        "        amin = 1e-10\n",
        "        top_db = None\n",
        "\n",
        "        # Spectrogram extractor\n",
        "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
        "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Logmel feature extractor\n",
        "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
        "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Spec augmenter\n",
        "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
        "            freq_drop_width=8, freq_stripes_num=2)\n",
        "\n",
        "        self.bn0 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
        "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
        "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
        "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
        "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
        "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
        "        self.fc_audioset1 = nn.Linear(2048, classes_num, bias=True)\n",
        "        \n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        init_bn(self.bn0)\n",
        "        init_layer(self.fc1)\n",
        "        init_layer(self.fc_audioset1)\n",
        " \n",
        "    def forward(self, input, spec_aug=False, mixup_lambda=None):\n",
        "        \"\"\"\n",
        "        Input: (batch_size, data_length)\"\"\"\n",
        "\n",
        "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
        "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
        "        #x = input\n",
        "        x = x.transpose(1, 3)\n",
        "        x = self.bn0(x)\n",
        "        x = x.transpose(1, 3)\n",
        "\n",
        "        if spec_aug:\n",
        "            x = self.spec_augmenter(x)\n",
        "\n",
        "        # Mixup on spectrogram\n",
        "        if mixup_lambda is not None:\n",
        "            x = do_mixup(x, mixup_lambda)\n",
        "        \n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        \n",
        "        (x1, _) = torch.max(x, dim=2)\n",
        "        x2 = torch.mean(x, dim=2)\n",
        "        x = x1 + x2\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu_(self.fc1(x))\n",
        "        #embedding = F.dropout(x, p=0.5, training=self.training)\n",
        "        clipwise_output = self.fc_audioset1(x)\n",
        "        \n",
        "        #output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
        "\n",
        "        return clipwise_output\n",
        "\n",
        "class BirdClassifier(nn.Module):\n",
        "    def __init__(self, encoder, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
        "        super().__init__()\n",
        "\n",
        "        window = 'hann'\n",
        "        center = True\n",
        "        pad_mode = 'reflect'\n",
        "        ref = 1.0\n",
        "        amin = 1e-10\n",
        "        top_db = None\n",
        "        \n",
        "        # Spectrogram extractor\n",
        "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
        "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Logmel feature extractor\n",
        "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
        "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Spec augmenter\n",
        "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
        "            freq_drop_width=8, freq_stripes_num=2)\n",
        "\n",
        "        self.encoder = encoder_params[encoder][\"init_op\"]()\n",
        "        self.avg_pool = AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.fc = Linear(encoder_params[encoder]['features'], classes_num)\n",
        "\n",
        "    def forward(self, input, spec_aug=False, mixup_lambda=None):\n",
        "\n",
        "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
        "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
        "\n",
        "        if spec_aug:\n",
        "            x = self.spec_augmenter(x)\n",
        "\n",
        "        # Mixup on spectrogram\n",
        "        if mixup_lambda is not None:\n",
        "            x = do_mixup(x, mixup_lambda)\n",
        "\n",
        "        x = self.encoder.forward_features(x)\n",
        "        x = self.avg_pool(x).flatten(1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Cnn14_DecisionLevelAtt(nn.Module):\n",
        "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
        "        fmax, classes_num):\n",
        "        \n",
        "        super(Cnn14_DecisionLevelAtt, self).__init__()\n",
        "\n",
        "        window = 'hann'\n",
        "        center = True\n",
        "        pad_mode = 'reflect'\n",
        "        ref = 1.0\n",
        "        amin = 1e-10\n",
        "        top_db = None\n",
        "        self.interpolate_ratio = 32     # Downsampled ratio\n",
        "\n",
        "        # Spectrogram extractor\n",
        "        self.spectrogram_extractor2 = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
        "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Logmel feature extractor\n",
        "        self.logmel_extractor2 = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
        "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Spec augmenter\n",
        "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
        "            freq_drop_width=8, freq_stripes_num=2)\n",
        "\n",
        "        self.bn0 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
        "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
        "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
        "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
        "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
        "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
        "        self.att_block2 = AttBlock(2048, classes_num, activation='sigmoid')\n",
        "        \n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        init_bn(self.bn0)\n",
        "        init_layer(self.fc1)\n",
        " \n",
        "    def forward(self, input, spec_aug=False, mixup_lambda=None):\n",
        "        \"\"\"\n",
        "        Input: (batch_size, data_length)\"\"\"\n",
        "\n",
        "        x = self.spectrogram_extractor2(input)   # (batch_size, 1, time_steps, freq_bins)\n",
        "        x = self.logmel_extractor2(x)    # (batch_size, 1, time_steps, mel_bins)\n",
        "\n",
        "        frames_num = x.shape[2]\n",
        "        \n",
        "        x = x.transpose(1, 3)\n",
        "        x = self.bn0(x)\n",
        "        x = x.transpose(1, 3)\n",
        "        \n",
        "        if spec_aug:\n",
        "            x = self.spec_augmenter(x)\n",
        "\n",
        "        # Mixup on spectrogram\n",
        "        if mixup_lambda is not None:\n",
        "            x = do_mixup(x, mixup_lambda)\n",
        "        \n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        \n",
        "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x = x1 + x2\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu_(self.fc1(x))\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        (clipwise_output, _, segmentwise_output) = self.att_block2(x)\n",
        "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "\n",
        "        # Get framewise output\n",
        "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)\n",
        "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
        "\n",
        "        output_dict = {'framewise_output': framewise_output, \n",
        "            'clipwise_output': clipwise_output}\n",
        "\n",
        "        return output_dict[\"clipwise_output\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting classifiers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt1g8QbqtAlc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d8895ff-a102-47a0-cae1-c314271fc4bf"
      },
      "source": [
        "%%writefile dataset.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "from albumentations.pytorch.functional import img_to_tensor\n",
        "\n",
        "from bird_codes import BIRD_CODE, INV_BIRD_CODE\n",
        "\n",
        "class PANNsDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_list: List[List[str]],\n",
        "        period=1,\n",
        "        transforms=None,\n",
        "        train=True,\n",
        "        waveform_transforms=None):\n",
        "\n",
        "        self.file_list = file_list\n",
        "        self.period = period\n",
        "        self.transforms = transforms\n",
        "        self.train = train\n",
        "        self.waveform_transforms = waveform_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "        \n",
        "        wav_path, ebird_code, pred_prob = self.file_list[idx]\n",
        "\n",
        "        y, sr = sf.read(wav_path)\n",
        "\n",
        "        if not self.train:\n",
        "            self.period = self.period\n",
        "\n",
        "        if self.waveform_transforms:\n",
        "            y = self.waveform_transforms(y, sample_rate=sr)\n",
        "        else:\n",
        "            len_y = len(y)\n",
        "            effective_length = sr * self.period\n",
        "            if len_y < effective_length:\n",
        "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
        "                start = np.random.randint(effective_length - len_y)\n",
        "                new_y[start:start + len_y] = y\n",
        "                y = new_y.astype(np.float32)\n",
        "            elif len_y > effective_length:\n",
        "                start = np.random.randint(len_y - effective_length)\n",
        "                y = y[start:start + effective_length].astype(np.float32)\n",
        "            else:\n",
        "                y = y.astype(np.float32)\n",
        "        \n",
        "        #if self.transforms:\n",
        "        #    pass\n",
        "            #spec, sr = self.transforms(data=(y, sr))['data']\n",
        "            #spec = np.expand_dims(spec, axis=0) #np.transpose(spec, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "            \n",
        "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
        "        if self.train:\n",
        "            if np.random.random() > 0.5:\n",
        "                labels[BIRD_CODE[ebird_code]] = pred_prob\n",
        "            else:\n",
        "                labels[BIRD_CODE[ebird_code]] = 1\n",
        "        #labels = BIRD_CODE[ebird_code]\n",
        "        else:\n",
        "            #ebird_code = ebird_code.split(' ')\n",
        "            #print(ebird_code)\n",
        "            #for eb in ebird_code:\n",
        "            labels[BIRD_CODE[ebird_code]] = 1\n",
        "\n",
        "\n",
        "        return {\n",
        "            \"waveform\" : y, #torch.tensor(spec, dtype=torch.float),\n",
        "            \"targets\" : labels, #torch.tensor(labels, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __get_labels__(self):\n",
        "        return np.array(self.file_list)[:, 1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF0LZJ7YtAiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e89c21b0-7f72-4988-db1b-0b03a85c4c6e"
      },
      "source": [
        "%%writefile audio_albu.py\n",
        "\n",
        "import audiomentations as A\n",
        "\n",
        "augmenter = A.Compose([\n",
        "    A.AddGaussianNoise(p=0.3),\n",
        "    A.AddGaussianSNR(p=0.3),\n",
        "    #A.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n",
        "    #A.AddImpulseResponse(p=1),\n",
        "    #A.AddShortNoises(\"../input/train_audio/\", p=1)\n",
        "    A.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.2),\n",
        "    A.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.2),\n",
        "    A.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.3),\n",
        "    A.Shift(p=0.3),\n",
        "    A.Normalize(p=0.3),\n",
        "    A.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.3),\n",
        "    A.PolarityInversion(p=0.3),\n",
        "    A.Gain(p=0.3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting audio_albu.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVUQYY5QxaxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eef8ad8-88fb-43fc-8a14-bc7a1055eb62"
      },
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def convert_onehot(x, max=54):\n",
        "    return np.eye(max)[x]\n",
        "\n",
        "def row_wise_f1_score_micro_numpy(y_true, y_pred, threshold=0.5, count=5):\n",
        "    \"\"\" \n",
        "    @author shonenkov \n",
        "    \n",
        "    y_true - 2d npy vector with gt\n",
        "    y_pred - 2d npy vector with prediction\n",
        "    threshold - for round labels\n",
        "    count - number of preds (used sorting by confidence)\n",
        "    \"\"\"\n",
        "    def meth_agn_v2(x, threshold):\n",
        "        idx, = np.where(x > threshold)\n",
        "        return idx[np.argsort(x[idx])[::-1]]\n",
        "\n",
        "    F1 = []\n",
        "    for preds, trues in zip(y_pred, y_true):\n",
        "        TP, FN, FP = 0, 0, 0\n",
        "        preds = meth_agn_v2(preds, threshold)[:count]\n",
        "        trues = meth_agn_v2(trues, threshold)\n",
        "        for true in trues:\n",
        "            if true in preds:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "        for pred in preds:\n",
        "            if pred not in trues:\n",
        "                FP += 1\n",
        "        F1.append(2*TP / (2*TP + FN + FP))\n",
        "    return np.mean(F1)\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "class MetricMeter(object):\n",
        "\n",
        "    def __init__(self, train=True):\n",
        "        self.reset()\n",
        "        self.train = train\n",
        "    \n",
        "    def reset(self):\n",
        "        self.y_true = []\n",
        "        self.y_pred = []\n",
        "        self.y_true_ = []\n",
        "        self.y_pred_ = []\n",
        "        self.acc = 0\n",
        "        self.f1 = 0\n",
        "        self.map = 0\n",
        "    \n",
        "    def update(self, y_true, y_pred):\n",
        "        self.y_true.extend(y_true.cpu().detach().numpy().tolist()) \n",
        "        self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "        \n",
        "    \n",
        "    @property\n",
        "    def avg(self):\n",
        "\n",
        "        #self.y_true = np.concatenate(self.y_true, axis=0)\n",
        "        #self.y_pred = np.concatenate(self.y_pred, axis=0)\n",
        "\n",
        "        #print(self.y_true[0])\n",
        "        #print(self.y_pred[0])\n",
        "\n",
        "        #print(self.y_ture.shape, self.y_pred.shape)\n",
        "\n",
        "        if self.train:\n",
        "            self.acc = metrics.accuracy_score(np.argmax(self.y_true, axis=1), np.argmax(self.y_pred, axis=1))\n",
        "            self.auc = 0#metrics.roc_auc_score(self.y_true, self.y_pred, average=None)\n",
        "            self.f1 = 0#metrics.f1_score(np.argmax(self.y_true, axis=1), np.argmax(self.y_true, axis=1), average=None)\n",
        "            self.map = 0#np.mean(metrics.average_precision_score(self.y_true, self.y_pred)\n",
        "            self.row_f1 = 0\n",
        "        else:\n",
        "            self.acc = metrics.accuracy_score(np.argmax(self.y_true, axis=1), np.argmax(self.y_pred, axis=1))\n",
        "            self.auc = 0 #np.mean(metrics.roc_auc_score(self.y_true, self.y_pred, average=None))\n",
        "            self.f1 = metrics.f1_score(np.argmax(self.y_true, axis=1), np.argmax(self.y_pred, axis=1), average='macro')\n",
        "            self.map = np.nan_to_num(\n",
        "                    np.mean(metrics.average_precision_score(self.y_true, self.y_pred, average=None))\n",
        "                ).mean()\n",
        "            \n",
        "            self.row_f1 = row_wise_f1_score_micro_numpy(np.array(self.y_true), np.array(self.y_pred))\n",
        "\n",
        "        return {\n",
        "            \"acc\" : self.acc,\n",
        "            \"f1\" : self.f1,\n",
        "            \"auc\" : self.auc,\n",
        "            \"map\" : self.map,\n",
        "            \"row_f1\" : self.row_f1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-uGaUUBxgVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4fff8cc-2eba-4ea2-a99a-dd7ae6f09c9d"
      },
      "source": [
        "%%writefile losses.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PANNsLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.cel = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        input_ = input\n",
        "        input_ = torch.where(\n",
        "            torch.isnan(input_),\n",
        "            torch.zeros_like(input_),\n",
        "            input_\n",
        "        )\n",
        "        input_ = torch.where(\n",
        "            torch.isinf(input_),\n",
        "            torch.zeros_like(input_),\n",
        "            input_\n",
        "        )\n",
        "\n",
        "        target = target.float()\n",
        "        \"\"\"\n",
        "\n",
        "        #return self.bce(input_, target)\n",
        "        return self.bce(input, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting losses.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuy5aUuXxikS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88b6da66-a67f-4dfc-9469-bd80b31ca8e4"
      },
      "source": [
        "%%writefile bird_codes.py\n",
        "\n",
        "\"\"\"\n",
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'nocall': 54\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
        "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
        "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
        "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
        "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
        "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
        "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
        "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
        "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
        "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
        "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
        "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
        "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
        "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
        "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
        "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
        "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
        "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
        "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
        "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
        "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
        "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
        "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
        "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
        "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
        "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
        "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
        "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
        "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
        "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
        "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
        "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
        "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
        "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
        "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
        "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
        "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
        "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
        "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
        "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
        "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
        "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
        "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
        "}\n",
        "\n",
        "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting bird_codes.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ptGtg3xkd-"
      },
      "source": [
        "!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git >> quit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqWNrstsxmtk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fccb770-4388-4490-bd52-194bfb942045"
      },
      "source": [
        "%%writefile schedulers.py\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# Fix Warmup Bug\n",
        "from warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
        "\n",
        "\n",
        "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
        "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
        "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch > self.total_epoch:\n",
        "            if self.after_scheduler:\n",
        "                if not self.finished:\n",
        "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
        "                    self.finished = True\n",
        "                return self.after_scheduler.get_lr()\n",
        "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
        "        if self.multiplier == 1.0:\n",
        "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting schedulers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yTMOL1uxoL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df33936b-6442-48a4-81cb-bccfb9508ed4"
      },
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import cv2\n",
        "import audioread\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import librosa\n",
        "import librosa.display as display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from IPython.display import Audio\n",
        "from pathlib import Path\n",
        "from typing import Optional, List\n",
        "\n",
        "from catalyst.data.sampler import DistributedSampler, BalanceClassSampler\n",
        "#from catalyst.dl import SupervisedRunner, State, CallbackOrder, Callback, CheckpointCallback\n",
        "from fastprogress import progress_bar\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "\n",
        "import classifiers\n",
        "import losses\n",
        "import dataset\n",
        "\n",
        "from audio_albu import augmenter\n",
        "from config import args\n",
        "from utils import AverageMeter, MetricMeter\n",
        "from schedulers import GradualWarmupSchedulerV2\n",
        "from pytorch_utils import do_mixup, Mixup, move_data_to_device\n",
        "\n",
        "mixup_augmenter = Mixup(mixup_alpha=1.)\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    \n",
        "    #if alpha > 0:\n",
        "    #    lam = np.random.beta(alpha, alpha)\n",
        "    #else:\n",
        "    #    lam = 1\n",
        "    \n",
        "    batch_size = x.size()[0]\n",
        "\n",
        "    if use_cuda:\n",
        "        index0 = torch.randperm(batch_size).cuda()\n",
        "        index1 = torch.randperm(batch_size).cuda()\n",
        "        index2 = torch.randperm(batch_size).cuda()\n",
        "        index3 = torch.randperm(batch_size).cuda()\n",
        "        index4 = torch.randperm(batch_size).cuda()\n",
        "\n",
        "    else:\n",
        "        index = torch.randperam(bath_size)\n",
        "    \n",
        "    #mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "\n",
        "    ind = random.choice([0,1,2,3,4])\n",
        "\n",
        "    if ind == 0:\n",
        "        mixed_x = x\n",
        "        mixed_y = y\n",
        "    elif ind == 1:\n",
        "        mixed_x = torch.cat([x, x[index1, :]], dim=1)\n",
        "        mixed_y = y + y[index1, :]\n",
        "    elif ind == 2:\n",
        "        mixed_x = torch.cat([x, x[index1, :], x[index2]], dim=1)\n",
        "        mixed_y = y + y[index1, :] + y[index2, :]\n",
        "    elif ind == 3:\n",
        "        mixed_x = torch.cat([x, x[index1, :], x[index2], x[index3, :]], dim=1)\n",
        "        mixed_y = y + y[index1, :] + y[index2, :] + y[index3, :]\n",
        "    elif ind == 4:\n",
        "        mixed_x = torch.cat([x, x[index1, :], x[index2], x[index3, :], x[index4, :]], dim=1)\n",
        "        mixed_y = y + y[index1, :] + y[index2, :] + y[index3, :] + y[index4, :]\n",
        "    \n",
        "    #mixed_y = torch.clamp(mixed_y, min=0, max=1)\n",
        "\n",
        "    \"\"\"\n",
        "    if np.random.random() > 0.5:\n",
        "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "        mixed_y = lam * y + (1 - lam) * y[index, :]\n",
        "    else:\n",
        "        mixed_x =  x + x[index, :]\n",
        "        mixed_y =  y + y[index, :]\n",
        "        \n",
        "    \"\"\"\n",
        "    return mixed_x, mixed_y\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "def train_epoch(args, model, loader, criterion, optimizer, epoch):\n",
        "    losses = AverageMeter()\n",
        "    scores = MetricMeter(train=True)\n",
        "\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    t = tqdm(loader, total=1000)\n",
        "    for i, sample in enumerate(t):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input = sample['waveform'].to(args.device)\n",
        "        target = sample['targets'].to(args.device)\n",
        "\n",
        "        if args.new_mixup:\n",
        "            input, target = mixup_data(input, target, args.alpha, True)\n",
        "        \n",
        "        ran = np.random.random()\n",
        "\n",
        "        if args.mixup and ran > 0.5:\n",
        "            mixup_lambda = mixup_augmenter.get_lambda(\n",
        "                batch_size=len(input)\n",
        "            )\n",
        "            mixup_lambda = move_data_to_device(mixup_lambda, args.device)\n",
        "\n",
        "            target = do_mixup(target, mixup_lambda)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=False):\n",
        "            if args.mixup and ran > 0.5:\n",
        "                output = model(input, True, mixup_lambda)\n",
        "            else:\n",
        "                output = model(input, True)\n",
        "            \n",
        "            #print(target.sum(dim=1))\n",
        "            #print(input.shape)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #scheduler.step()\n",
        "\n",
        "        bs = input.size(0)\n",
        "        scores.update(target, output)\n",
        "        losses.update(loss.item(), bs)\n",
        "\n",
        "        t.set_description(f\"Train E:{epoch} - Loss:{losses.avg:0.4f}\")\n",
        "\n",
        "        if i == 1000:\n",
        "            break\n",
        "\n",
        "    t.close()\n",
        "\n",
        "    return scores.avg, losses.avg\n",
        "\n",
        "def valid_epoch(args, model, loader, criterion, epoch):\n",
        "    losses = AverageMeter()\n",
        "    scores = MetricMeter(train=False)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        t = tqdm(loader)\n",
        "        for i, sample in enumerate(t):\n",
        "\n",
        "            input = sample['waveform'].to(args.device)\n",
        "            target = sample['targets'].to(args.device)\n",
        "\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            bs = input.size(0)\n",
        "            scores.update(target, output)\n",
        "            losses.update(loss.item(), bs)\n",
        "\n",
        "            t.set_description(f\"Valid E:{epoch} - Loss:{losses.avg:0.4f}\")\n",
        "\n",
        "    t.close()\n",
        "\n",
        "    return scores.avg, losses.avg\n",
        "\n",
        "def main(fold):\n",
        "\n",
        "    # Setting seed\n",
        "    seed = args.seed\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    args.fold = fold\n",
        "    args.save_path = os.path.join(args.output_dir, args.exp_name)\n",
        "    os.makedirs(args.save_path, exist_ok=True)\n",
        "\n",
        "    model = classifiers.__dict__[args.network](**args.model_config)\n",
        "    if args.pretrained_path:\n",
        "        weights = torch.load(args.pretrained_path, map_location=args.device)\n",
        "        model.load_state_dict(weights[\"model\"], strict=False)\n",
        "    \n",
        "    model = model.to(args.device)\n",
        "\n",
        "    criterion = losses.__dict__[args.losses]()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.init_lr)\n",
        "\n",
        "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, args.epochs)\n",
        "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
        "    \n",
        "    train_df = pd.read_csv(args.train_csv)\n",
        "    #valid_df = pd.read_csv(args.valid_csv)\n",
        "    if args.DEBUG:\n",
        "        train_df = train_df.sample(1000)\n",
        "        #valid_df = valid_df.sample(1000)\n",
        "    \n",
        "    train_fold = train_df[train_df.kfold != fold]\n",
        "    valid_fold = train_df[train_df.kfold.isin([fold])]\n",
        "\n",
        "    #print(valid_fold.head())\n",
        "\n",
        "    valid_fold = valid_fold[valid_fold.ebird_code == valid_fold.pred_code]\n",
        "\n",
        "    #print(valid_fold.head())\n",
        "\n",
        "    train_file_list = train_fold[['path', 'pred_code', 'pred_prob']].values.tolist()\n",
        "    valid_file_list = valid_fold[['path', 'pred_code', 'pred_prob']].values.tolist()\n",
        "\n",
        "    train_dataset = dataset.PANNsDataset(\n",
        "        train_file_list,\n",
        "        period=args.PERIOD,\n",
        "        transforms=augmenter,#train_transforms(args.mel_param),\n",
        "        train=True\n",
        "    )\n",
        "    valid_dataset = dataset.PANNsDataset(\n",
        "        valid_file_list,\n",
        "        period=args.PERIOD,\n",
        "        transforms=False,#valid_transforms(args.mel_param)\n",
        "        train=False\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        #sampler = BalanceClassSampler(labels=train_dataset.__get_labels__(), mode=\"upsampling\"),\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "    print(\".................... Training started .................\")\n",
        "\n",
        "    best_map = -999999\n",
        "    best_f1  = -999999\n",
        "    best_row_f1 = -99999\n",
        "\n",
        "    if args.load_from:\n",
        "        # \"drive/My Drive/Cornell Birdcall Identification/weights/Cnn14_16k_5\"\n",
        "        weights = torch.load(os.path.join(\"drive/My Drive/Cornell Birdcall Identification/weights/Cnn14_16k_5\", f\"fold-{args.fold}.bin\"))\n",
        "        model.load_state_dict(weights[\"model\"], strict=False)\n",
        "        #optimizer.load_state_dict(weights[\"optimizer\"])\n",
        "        #scheduler_warmup.load_state_dict(weights[\"scheduler_warmup\"])\n",
        "        #args.start_epoch = weights[\"epoch\"] + 1\n",
        "        #best_map = 0.6212948058165978\n",
        "        \n",
        "        model = model.to(args.device)\n",
        "\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "\n",
        "        #scheduler_warmup.step(epoch)\n",
        "\n",
        "        train_avg, train_loss = train_epoch(\n",
        "            args,\n",
        "            model,\n",
        "            train_loader,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            epoch\n",
        "        )\n",
        "\n",
        "        valid_avg, valid_loss = valid_epoch(\n",
        "            args,\n",
        "            model,\n",
        "            valid_loader,\n",
        "            criterion,\n",
        "            epoch\n",
        "        )\n",
        "\n",
        "        scheduler_warmup.step()    \n",
        "        if epoch==2: scheduler_warmup.step() # bug workaround \n",
        "\n",
        "        content = f\"\"\"\n",
        "                {time.ctime()} \\n\n",
        "                Fold:{args.fold}, Epoch:{epoch}, lr:{optimizer.param_groups[0]['lr']:.7}, \\n\n",
        "                Train Loss:{train_loss:0.4f} - ACC:{train_avg['acc']:0.4f} - F1:{train_avg['f1']:0.4f} - MAP:{train_avg['map']:0.4f}  \\n\n",
        "                Valid Loss:{valid_loss:0.4f} - ACC:{valid_avg['acc']:0.4f} - F1:{valid_avg['f1']:0.4f} - ROW_F1:{valid_avg['row_f1']:0.4f} - MAP:{valid_avg['map']:0.4f} \\n\\n\n",
        "        \"\"\"\n",
        "        print(content)\n",
        "\n",
        "        with open(f'{args.save_path}/log_{args.exp_name}.txt', 'a') as appender:\n",
        "            appender.write(content + '\\n')\n",
        "        \n",
        "        if valid_avg[\"map\"] > best_map:\n",
        "            print(f\"######### >>>>>>> Model Improved from {best_map} -----> {valid_avg['map']}\")\n",
        "            checkpoint = { \n",
        "                'epoch': epoch,\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler_warmup': scheduler_warmup.state_dict()\n",
        "            }\n",
        "\n",
        "            torch.save(checkpoint, os.path.join(args.save_path, f\"checkpoint-fold-{args.fold}.bin\"))\n",
        "            torch.save(model.state_dict(), os.path.join(args.save_path, f\"fold-{args.fold}.bin\"))\n",
        "\n",
        "            best_map = valid_avg[\"map\"]\n",
        "        \n",
        "        torch.save(model.state_dict(), os.path.join(args.save_path, f\"last-fold-{args.fold}.bin\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    for fold in range(5):\n",
        "        print(\"#\"*20)\n",
        "        print(f\"####### FOLD : {fold}\")\n",
        "        if fold == 0:\n",
        "            main(fold)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke4sX-ekRb_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "492c0a4f-dac3-4572-f80c-1190ea20577d"
      },
      "source": [
        "!wget https://zenodo.org/record/3987831/files/Cnn14_DecisionLevelAtt_mAP%3D0.425.pth?download=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-12 08:29:03--  https://zenodo.org/record/3987831/files/Cnn14_DecisionLevelAtt_mAP%3D0.425.pth?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 331757477 (316M) [application/octet-stream]\n",
            "Saving to: Cnn14_DecisionLevelAtt_mAP=0.425.pth?download=1.1\n",
            "\n",
            "Cnn14_DecisionLevel 100%[===================>] 316.39M  6.00MB/s    in 45s     \n",
            "\n",
            "2020-09-12 08:29:50 (6.99 MB/s) - Cnn14_DecisionLevelAtt_mAP=0.425.pth?download=1.1 saved [331757477/331757477]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnyDbHcRyGj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dec74e13-81b3-4b19-aebc-6d2670d96a33"
      },
      "source": [
        "%%writefile config.py\n",
        "\n",
        "class args:\n",
        "\n",
        "    DEBUG = False\n",
        "\n",
        "    mixup = True\n",
        "\n",
        "    new_mixup = False\n",
        "\n",
        "    alpha = 1\n",
        "\n",
        "    exp_name = \"stage1_Cnn14_DecisionLevelAtt_1sec_aug\"\n",
        "    output_dir = \"drive/My Drive/Cornell Birdcall Identification/weights\"\n",
        "    train_csv = \"drive/My Drive/Cornell Birdcall Identification/input/stage1_sudo.csv\"\n",
        "    valid_csv = \"drive/My Drive/Cornell Birdcall Identification/input/valid_stage1_df3.csv\"\n",
        "    pretrained_path = \"Cnn14_DecisionLevelAtt_mAP=0.425.pth?download=1\" #False #\"Cnn14_16k_mAP=0.438.pth?download=1\"\n",
        "\n",
        "    network = \"Cnn14_DecisionLevelAtt\" #\"Cnn14_16k\" #\"BirdClassifier\"\n",
        "    encoder = \"resnest50d\"\n",
        "\n",
        "    losses = \"PANNsLoss\"\n",
        "\n",
        "    mel_param = {\n",
        "        #\"hop_lenght\" : 345 * 2,\n",
        "        \"fmin\" : 20,\n",
        "        \"fmax\" : 16000 // 2,\n",
        "        \"n_mels\" : 128,\n",
        "        \"n_fft\" : 128 * 20\n",
        "    }\n",
        "\n",
        "    model_config = {\n",
        "        #\"encoder\" : \"resnest50d\",\n",
        "        \"sample_rate\": 16000,\n",
        "        \"window_size\": 512,\n",
        "        \"hop_size\": 160,\n",
        "        \"mel_bins\": 64,\n",
        "        \"fmin\": 50,\n",
        "        \"fmax\": 8000,\n",
        "        \"classes_num\": 264 #209 #54 #264\n",
        "    }\n",
        "\n",
        "    PERIOD = 1\n",
        "    \n",
        "    device = \"cuda\"\n",
        "    seed = 42\n",
        "    epochs = 50\n",
        "    batch_size = 32 * 4\n",
        "    num_workers = 4\n",
        "    start_epoch = 0\n",
        "\n",
        "    warmup_epo = 2\n",
        "    cosine_epo = 8\n",
        "    init_lr = 3e-5\n",
        "\n",
        "    load_from = False\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting config.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p19cZaXB8pef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1993d0c5-d172-4ca2-cef6-1722fdade809"
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "####### FOLD : 0\n",
            ".................... Training started .................\n",
            "Train E:0 - Loss:0.7652: 100% 1000/1000 [05:37<00:00,  2.97it/s]\n",
            "Valid E:0 - Loss:0.6953: 100% 616/616 [01:15<00:00,  8.15it/s]\n",
            "\n",
            "                Sat Sep 12 08:37:33 2020 \n",
            "\n",
            "                Fold:0, Epoch:0, lr:0.0003, \n",
            "\n",
            "                Train Loss:0.7652 - ACC:0.0044 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6953 - ACC:0.0049 - F1:0.0004 - ROW_F1:0.0059 - MAP:0.0046 \n",
            "\n",
            "\n",
            "        \n",
            "######### >>>>>>> Model Improved from -999999 -----> 0.004605226564525975\n",
            "Train E:1 - Loss:0.6932: 100% 1000/1000 [05:38<00:00,  2.96it/s]\n",
            "Valid E:1 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.25it/s]\n",
            "\n",
            "                Sat Sep 12 08:44:24 2020 \n",
            "\n",
            "                Fold:0, Epoch:1, lr:0.0003, \n",
            "\n",
            "                Train Loss:0.6932 - ACC:0.0041 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0053 - F1:0.0006 - ROW_F1:0.0063 - MAP:0.0048 \n",
            "\n",
            "\n",
            "        \n",
            "######### >>>>>>> Model Improved from 0.004605226564525975 -----> 0.004785208067429247\n",
            "Train E:2 - Loss:0.6931: 100% 1000/1000 [05:37<00:00,  2.96it/s]\n",
            "Valid E:2 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.14it/s]\n",
            "\n",
            "                Sat Sep 12 08:51:16 2020 \n",
            "\n",
            "                Fold:0, Epoch:2, lr:0.0002988172, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0041 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0061 - F1:0.0005 - ROW_F1:0.0027 - MAP:0.0046 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:3 - Loss:0.6931: 100% 1000/1000 [05:39<00:00,  2.94it/s]\n",
            "Valid E:3 - Loss:0.6931: 100% 616/616 [00:47<00:00, 13.05it/s]\n",
            "\n",
            "                Sat Sep 12 08:58:01 2020 \n",
            "\n",
            "                Fold:0, Epoch:3, lr:0.0002973431, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0042 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0056 - F1:0.0003 - ROW_F1:0.0008 - MAP:0.0044 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:4 - Loss:0.6931: 100% 1000/1000 [05:37<00:00,  2.96it/s]\n",
            "Valid E:4 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.17it/s]\n",
            "\n",
            "                Sat Sep 12 09:04:44 2020 \n",
            "\n",
            "                Fold:0, Epoch:4, lr:0.0002952875, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0039 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0052 - F1:0.0002 - ROW_F1:0.0003 - MAP:0.0042 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:5 - Loss:0.6931: 100% 1000/1000 [05:37<00:00,  2.97it/s]\n",
            "Valid E:5 - Loss:0.6931: 100% 616/616 [00:47<00:00, 13.06it/s]\n",
            "\n",
            "                Sat Sep 12 09:11:26 2020 \n",
            "\n",
            "                Fold:0, Epoch:5, lr:0.0002926585, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0042 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0049 - F1:0.0002 - ROW_F1:0.0001 - MAP:0.0041 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:6 - Loss:0.6931: 100% 1000/1000 [05:38<00:00,  2.95it/s]\n",
            "Valid E:6 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.26it/s]\n",
            "\n",
            "                Sat Sep 12 09:18:08 2020 \n",
            "\n",
            "                Fold:0, Epoch:6, lr:0.0002894665, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0038 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0048 - F1:0.0001 - ROW_F1:0.0001 - MAP:0.0040 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:7 - Loss:0.6931: 100% 1000/1000 [05:38<00:00,  2.95it/s]\n",
            "Valid E:7 - Loss:0.6931: 100% 616/616 [00:47<00:00, 13.05it/s]\n",
            "\n",
            "                Sat Sep 12 09:24:52 2020 \n",
            "\n",
            "                Fold:0, Epoch:7, lr:0.0002857241, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0041 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0048 - F1:0.0001 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:8 - Loss:0.6931: 100% 1000/1000 [05:37<00:00,  2.96it/s]\n",
            "Valid E:8 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.20it/s]\n",
            "\n",
            "                Sat Sep 12 09:31:34 2020 \n",
            "\n",
            "                Fold:0, Epoch:8, lr:0.000281446, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0042 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:9 - Loss:0.6931: 100% 1000/1000 [05:35<00:00,  2.98it/s]\n",
            "Valid E:9 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.14it/s]\n",
            "\n",
            "                Sat Sep 12 09:38:13 2020 \n",
            "\n",
            "                Fold:0, Epoch:9, lr:0.0002766492, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0042 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:10 - Loss:0.6931: 100% 1000/1000 [05:33<00:00,  3.00it/s]\n",
            "Valid E:10 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.29it/s]\n",
            "\n",
            "                Sat Sep 12 09:44:50 2020 \n",
            "\n",
            "                Fold:0, Epoch:10, lr:0.0002713525, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0036 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:11 - Loss:0.6931: 100% 1000/1000 [05:35<00:00,  2.98it/s]\n",
            "Valid E:11 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.14it/s]\n",
            "\n",
            "                Sat Sep 12 09:51:30 2020 \n",
            "\n",
            "                Fold:0, Epoch:11, lr:0.000265577, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0039 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:12 - Loss:0.6931: 100% 1000/1000 [05:35<00:00,  2.98it/s]\n",
            "Valid E:12 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.27it/s]\n",
            "\n",
            "                Sat Sep 12 09:58:09 2020 \n",
            "\n",
            "                Fold:0, Epoch:12, lr:0.0002593453, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0040 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0039 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:13 - Loss:0.6931: 100% 1000/1000 [05:35<00:00,  2.98it/s]\n",
            "Valid E:13 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.15it/s]\n",
            "\n",
            "                Sat Sep 12 10:04:49 2020 \n",
            "\n",
            "                Fold:0, Epoch:13, lr:0.0002526821, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0040 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0038 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:14 - Loss:0.6931: 100% 1000/1000 [05:34<00:00,  2.99it/s]\n",
            "Valid E:14 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.28it/s]\n",
            "\n",
            "                Sat Sep 12 10:11:27 2020 \n",
            "\n",
            "                Fold:0, Epoch:14, lr:0.0002456136, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0039 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0038 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:15 - Loss:0.6931: 100% 1000/1000 [05:35<00:00,  2.98it/s]\n",
            "Valid E:15 - Loss:0.6931: 100% 616/616 [00:46<00:00, 13.19it/s]\n",
            "\n",
            "                Sat Sep 12 10:18:07 2020 \n",
            "\n",
            "                Fold:0, Epoch:15, lr:0.0002381678, \n",
            "\n",
            "                Train Loss:0.6931 - ACC:0.0039 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.6931 - ACC:0.0047 - F1:0.0000 - ROW_F1:0.0000 - MAP:0.0038 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:16 - Loss:0.6931:  22% 216/1000 [01:11<04:43,  2.77it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr5hcU1HzwPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40608ddd-1ad0-46b1-e9b7-858b10a4bbd9"
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "####### FOLD : 0\n",
            ".................... Training started .................\n",
            "Train E:0 - Loss:0.0133: 100% 1000/1000 [04:54<00:00,  3.40it/s]\n",
            "Valid E:0 - Loss:0.0043: 100% 833/833 [01:43<00:00,  8.04it/s]\n",
            "\n",
            "                Sat Sep 12 05:43:56 2020 \n",
            "\n",
            "                Fold:0, Epoch:0, lr:0.0003, \n",
            "\n",
            "                Train Loss:0.0133 - ACC:0.3695 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.0043 - ACC:0.8647 - F1:0.8357 - ROW_F1:0.7595 - MAP:0.8876 \n",
            "\n",
            "\n",
            "        \n",
            "######### >>>>>>> Model Improved from -999999 -----> 0.8876025344539631\n",
            "Train E:1 - Loss:0.0116: 100% 1000/1000 [04:56<00:00,  3.37it/s]\n",
            "Valid E:1 - Loss:0.0040: 100% 833/833 [01:42<00:00,  8.14it/s]\n",
            "\n",
            "                Sat Sep 12 05:51:08 2020 \n",
            "\n",
            "                Fold:0, Epoch:1, lr:0.0003, \n",
            "\n",
            "                Train Loss:0.0116 - ACC:0.4465 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.0040 - ACC:0.8519 - F1:0.8167 - ROW_F1:0.7587 - MAP:0.8932 \n",
            "\n",
            "\n",
            "        \n",
            "######### >>>>>>> Model Improved from 0.8876025344539631 -----> 0.8931790851570438\n",
            "Train E:2 - Loss:0.0109: 100% 1000/1000 [04:54<00:00,  3.39it/s]\n",
            "Valid E:2 - Loss:0.0041: 100% 833/833 [01:42<00:00,  8.15it/s]\n",
            "\n",
            "                Sat Sep 12 05:58:19 2020 \n",
            "\n",
            "                Fold:0, Epoch:2, lr:0.0002988172, \n",
            "\n",
            "                Train Loss:0.0109 - ACC:0.4861 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.0041 - ACC:0.8379 - F1:0.8031 - ROW_F1:0.7387 - MAP:0.8865 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:3 - Loss:0.0105: 100% 1000/1000 [04:55<00:00,  3.38it/s]\n",
            "Valid E:3 - Loss:0.0040: 100% 833/833 [01:42<00:00,  8.16it/s]\n",
            "\n",
            "                Sat Sep 12 06:05:24 2020 \n",
            "\n",
            "                Fold:0, Epoch:3, lr:0.0002973431, \n",
            "\n",
            "                Train Loss:0.0105 - ACC:0.5048 - F1:0.0000 - MAP:0.0000  \n",
            "\n",
            "                Valid Loss:0.0040 - ACC:0.8382 - F1:0.7990 - ROW_F1:0.7440 - MAP:0.8786 \n",
            "\n",
            "\n",
            "        \n",
            "Train E:4 - Loss:0.0104:  29% 287/1000 [01:25<03:16,  3.62it/s]Traceback (most recent call last):\n",
            "  File \"train.py\", line 333, in <module>\n",
            "    main(fold)\n",
            "  File \"train.py\", line 286, in main\n",
            "    epoch\n",
            "  File \"train.py\", line 144, in train_epoch\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 185, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 127, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "Train E:4 - Loss:0.0104:  29% 287/1000 [01:26<03:33,  3.33it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lgi6gVh0B-Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}